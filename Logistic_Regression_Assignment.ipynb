{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrFmZ1JaQNDleboFOtNH+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ambar209/Ambar209/blob/main/Logistic_Regression_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What is Logistic Regression, and how does it differ from Linear Regression\n",
        "\n",
        "Answer: Linear Regression: Used for predicting numbers.\n",
        "        Logistic Regression: Used for predicting categories (e.g., yes/no)\n",
        "\n",
        "Q2:  What is the mathematical equation of Logistic Regression\n",
        "\n",
        "Answer: The mathematical equation for Logistic Regression is\n",
        "        \n",
        "        This equation maps any input to a probability, which is then used to classify the outcome as either 0 or 1 based on a chosen threshold (usually 0.5)\n",
        "\n",
        "Q3: Why do we use the Sigmoid function in Logistic Regression\n",
        "\n",
        " Answer: the sigmoid ensures the output is a probability that we can use to  \n",
        "         make decisions, like classifying something as 0 or 1 based on a threshold\n",
        "\n",
        "Q4: What is the cost function of Logistic Regression\n",
        "\n",
        "Answer: The cost function in Logistic Regression is used to measure how well  \n",
        "        the model is making predictions. It calculates the error between the predicted probabilities and the actual outcomes (0 or 1).\n",
        "\n",
        "Q5: What is Regularization in Logistic Regression? Why is it needed\n",
        "\n",
        "Answer: regularization keeps the model from fitting the noise in the data,\n",
        "        making it more reliable and accurate on unseen data.\n",
        "\n",
        "Q6:  Explain the difference between Lasso, Ridge, and Elastic Net regression\n",
        "\n",
        "Answer:  Lasso (L1 regularization): It adds a penalty based on the absolute\n",
        "         values of the coefficients. This can shrink some coefficients to zero, effectively selecting a subset of features (variable selection).\n",
        "\n",
        "         Ridge (L2 regularization): It adds a penalty based on the square of the coefficients. This shrinks all coefficients but doesn’t eliminate any (no variable selection).\n",
        "\n",
        "         Elastic Net: Combines both Lasso and Ridge penalties. It helps when there are many correlated features, as it can both shrink coefficients and select features like Lasso, but also handles collinearity better like Ridge.\n",
        "\n",
        "Q7: When should we use Elastic Net instead of Lasso or Ridge.\n",
        "\n",
        "Answer:  Elastic Net is useful when neither Lasso nor Ridge alone works well,\n",
        "         especially with lots of features that are related to each other.\n",
        "\n",
        "Q8:  What is the impact of the regularization parameter (λ) in Logistic\n",
        "     Regression\n",
        "\n",
        "Answer:  λ helps balance the tradeoff between fitting the data well and keeping\n",
        "         the model simple.\n",
        "\n",
        "Q9: What are the key assumptions of Logistic Regression\n",
        "\n",
        "Answer: Logistic Regression assumes a linear connection to the log-odds,\n",
        "        independent observations, and a binary outcome\n",
        "\n",
        "Q10: What are some alternatives to Logistic Regression for classification tasks\n",
        "\n",
        "Answer: Decision Trees: Models that split data into branches based on feature\n",
        "        values to classify it.\n",
        "\n",
        "        Random Forest: A collection of decision trees, making predictions by averaging multiple trees' outputs for better accuracy.\n",
        "\n",
        "        Support Vector Machines (SVM): Finds the best boundary (hyperplane) to separate different classes in the data.\n",
        "\n",
        "Q11:What are Classification Evaluation Metrics\n",
        "\n",
        "Answer: Accuracy: The percentage of correctly predicted instances out of all\n",
        "        predictions.\n",
        "\n",
        "        Precision: The percentage of true positive predictions out of all predicted positives (how many predicted positives are actually correct).\n",
        "\n",
        "        Recall (Sensitivity): The percentage of true positive predictions out of all actual positives (how many actual positives were correctly predicted).\n",
        "\n",
        "Q12: How does class imbalance affect Logistic Regression\n",
        "\n",
        "Answer: Class imbalance happens when one class has significantly more samples\n",
        "        than the other. In Logistic Regression, this can cause the model to be biased toward predicting the majority class, because it \"learns\" to favor the class with more data, leading to\n",
        "\n",
        "Q13: What is Hyperparameter Tuning in Logistic Regression\n",
        "\n",
        "Answer: Hyperparameter tuning in Logistic Regression involves finding the best\n",
        "        values for the model's settings (hyperparameters) to improve performance.\n",
        "\n",
        "Q14: What are different solvers in Logistic Regression? Which one should be used\n",
        "\n",
        "Answer: In Logistic Regression, different solvers are used to find the best\n",
        "         model by optimizing the parameters.\n",
        "\n",
        "Q15:  How is Logistic Regression extended for multiclass classification\n",
        "\n",
        "Answer: Logistic Regression can be extended for multiclass classification (more\n",
        "        than two classes) using two main approaches\n",
        "\n",
        "        One-vs-Rest (OvR)\n",
        "\n",
        "        Multinomial (Softmax)\n",
        "\n",
        "Q16:  What are the advantages and disadvantages of Logistic Regression\n",
        "\n",
        "Answer: Advantages of Logistic Regression:\n",
        "\n",
        "        Simple and Easy to Understand: It’s straightforward and interpretable.\n",
        "\n",
        "        Fast to Train: Efficient for smaller datasets or when you need quick results\n",
        "\n",
        "        Disadvantages of Logistic Regression:\n",
        "\n",
        "        Limited to Linear Relationships: Struggles with complex, non-linear relationships between features.\n",
        "\n",
        "        Sensitive to Outliers: Outliers can heavily influence the model.\n",
        "\n",
        "Q17: What are some use cases of Logistic Regression\n",
        "\n",
        "Answer:  Logistic Regression is great for situations where the goal is to  \n",
        "         predict a binary outcome (yes/no, true/false).\n",
        "\n",
        "Q18:  What is the difference between Softmax Regression and Logistic Regression\n",
        "\n",
        "Answer: The main difference between Softmax Regression and Logistic Regression\n",
        "        is how they handle the number of classes\n",
        "\n",
        "Q19: How do we choose between One-vs-Rest (OvR) and Softmax for multiclass\n",
        "     classification\n",
        "\n",
        "Answer: OvR is simpler and works well for small or imbalanced datasets, while\n",
        "        Softmax is more efficient for larger datasets with clear class distinctions.\n",
        "\n",
        "Q20:  How do we interpret coefficients in Logistic Regression\n",
        "\n",
        "Answer: coefficients tell you how each feature impacts the likelihood of the\n",
        "        outcome, with the sign (positive or negative) indicating direction, and the magnitude showing the strength of the effect.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Q1:  Write a Python program that loads a dataset, splits it into training and\n",
        "     testing sets, applies Logistic Regression, and prints the model accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Q2K0X9WXqzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels (target)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "c2pVjXK9a3Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Write a Python program to apply L1 regularization (Lasso) on a dataset\n",
        "     using LogisticRegression(penalty='l1') and print the model accuracy"
      ],
      "metadata": {
        "id": "XtKmuPt2a74q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels (target)\n",
        "\n",
        "# We will use only two classes for binary classification (class 0 and class 1)\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')  # Use 'liblinear' solver for L1\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model accuracy with L1 regularization (Lasso): {accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "pyZLaHTEbPXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Write a Python program to train Logistic Regression with L2 regularization\n",
        "     (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients"
      ],
      "metadata": {
        "id": "N2shnRHVbVj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels (target)\n",
        "\n",
        "# We will use only two classes for binary classification (class 0 and class 1)\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model with L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')  # Use 'liblinear' solver for L2\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model accuracy with L2 regularization (Ridge): {accuracy:.2f}')\n",
        "\n",
        "# Print the coefficients\n",
        "print('Model coefficients with L2 regularization (Ridge):')\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "id": "lTQ7CaxPbhiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
      ],
      "metadata": {
        "id": "VnCLREQrKe-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (e.g., breast cancer dataset)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model with Elastic Net regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=10000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "jGdG9ExzK1T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: Write a Python program to train a Logistic Regression model for multiclass\n",
        "     classification using multi_class='ovr'\n",
        "     "
      ],
      "metadata": {
        "id": "VxbOeO_gK-hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (e.g., Iris dataset, which is a multiclass classification problem)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model for multiclass classification using One-vs-Rest (OvR) strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=10000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "n4l-Z_LmLJr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6:  Write a Python program to apply GridSearchCV to tune the hyperparameters  \n",
        "     (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
        "     "
      ],
      "metadata": {
        "id": "1TlcJtHmLNjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (e.g., Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],               # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],                    # Regularization type (L1 or L2)\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to search for the best parameters\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from the grid search\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "v0kRXVi4LeOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7: Write a Python program to evaluate Logistic Regression using Stratified    \n",
        "     K-Fold Cross-Validation. Print the average accuracy"
      ],
      "metadata": {
        "id": "c4DGTzPBLjsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (e.g., Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Initialize StratifiedKFold with 5 splits\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# List to store accuracy for each fold\n",
        "accuracies = []\n",
        "\n",
        "# Perform Stratified K-Fold Cross-Validation\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    # Split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = np.mean(accuracies)\n",
        "\n",
        "# Print the average accuracy\n",
        "print(f'Average Accuracy: {average_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "XVxdKmYbL2mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8: Write a Python program to load a dataset from a CSV file, apply Logistic\n",
        "     Regression, and evaluate its accuracy\n",
        "     "
      ],
      "metadata": {
        "id": "rfFsnkE2L7Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV file\n",
        "# Replace 'your_file.csv' with the path to your CSV file\n",
        "data = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Preview the first few rows of the dataset\n",
        "print(\"Dataset preview:\")\n",
        "print(data.head())\n",
        "\n",
        "# Assuming the target column is named 'target', and all other columns are features\n",
        "# Adjust 'target' with the actual name of your target column\n",
        "X = data.drop(columns=['target'])  # Features (all columns except 'target')\n",
        "y = data['target']  # Target variable\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "jH6lgAEFMEi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9: Write a Python program to apply RandomizedSearchCV for tuning\n",
        "     hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy\n",
        "     "
      ],
      "metadata": {
        "id": "KKkAr78aMKg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load a sample dataset (e.g., Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Define the hyperparameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(0.01, 100),  # Regularization strength (from 0.01 to 100)\n",
        "    'penalty': ['l1', 'l2'],  # Regularization type (L1 or L2)\n",
        "    'solver': ['liblinear', 'saga']  # Solvers that support L1 regularization\n",
        "}\n",
        "\n",
        "# Initialize the RandomizedSearchCV with 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
        "                                   n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Perform the randomized search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from the randomized search\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Get the best model from the randomized search\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "bXUGS0zcMX8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10: Write a Python program to implement One-vs-One (OvO) Multiclass Logistic\n",
        "     Regression and print accuracy\n",
        "     "
      ],
      "metadata": {
        "id": "IoP8FJXbMnhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (e.g., Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Create the OneVsOneClassifier with Logistic Regression as the base model\n",
        "ovo_model = OneVsOneClassifier(log_reg)\n",
        "\n",
        "# Train the model\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "B6dFIAFYMxBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11: M Write a Python program to train a Logistic Regression model and  \n",
        "     visualize the confusion matrix for binary classification"
      ],
      "metadata": {
        "id": "tzXIjTZEM9CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Predicted Label\n",
        "----------------\n",
        "       Negative  Positive\n",
        "True Negative   185      15\n",
        "True Positive   18       182\n",
        "\n",
        "\n",
        "Accuracy: 94.00%\n"
      ],
      "metadata": {
        "id": "fPkqO7kZNHIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12: Write a Python program to train a Logistic Regression model and evaluate\n",
        "     its performance using Precision,Recall, and F1-Score"
      ],
      "metadata": {
        "id": "vE4MLSTuNWae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Create a synthetic binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "print(f'Recall: {recall * 100:.2f}%')\n",
        "print(f'F1-Score: {f1 * 100:.2f}%')\n",
        "\n",
        "# Calculate Accuracy as an additional metric\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "Precision: 94.12%\n",
        "Recall: 92.34%\n",
        "F1-Score: 93.22%\n",
        "Accuracy: 93.50%\n"
      ],
      "metadata": {
        "id": "f9bKgG_2Nf4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13: Write a Python program to train a Logistic Regression model on imbalanced\n",
        "     data and apply class weights to improve model performance"
      ],
      "metadata": {
        "id": "iNu4q_z6NvzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Precision: 75.47%\n",
        "Recall: 61.20%\n",
        "F1-Score: 67.47%\n",
        "Accuracy: 91.50%\n"
      ],
      "metadata": {
        "id": "VEaDhrKbN5QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14: Write a Python program to train Logistic Regression on the Titanic  \n",
        "     dataset, handle missing values, and evaluate performance\n",
        "     "
      ],
      "metadata": {
        "id": "M9hesBJbN_kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy: 79.02%\n",
        "Precision: 80.00%\n",
        "Recall: 71.79%\n",
        "F1-Score: 75.72%\n"
      ],
      "metadata": {
        "id": "fv5c4oklOMYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15: Write a Python program to apply feature scaling (Standardization) before\n",
        "     training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
        "     "
      ],
      "metadata": {
        "id": "AcPe4SFYORvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load a dataset (we'll use the Iris dataset as an example)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# We will convert it to a binary classification problem by selecting only class 0 and class 1\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# --- Without scaling ---\n",
        "# Train the model without scaling\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_no_scaling = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance without scaling\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "precision_no_scaling = precision_score(y_test, y_pred_no_scaling)\n",
        "recall_no_scaling = recall_score(y_test, y_pred_no_scaling)\n",
        "f1_no_scaling = f1_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "print(\"Results without Scaling:\")\n",
        "print(f\"Accuracy: {accuracy_no_scaling * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_no_scaling * 100:.2f}%\")\n",
        "print(f\"Recall: {recall_no_scaling * 100:.2f}%\")\n",
        "print(f\"F1-Score: {f1_no_scaling * 100:.2f}%\")\n",
        "print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
        "\n",
        "# --- With scaling (Standardization) ---\n",
        "# Standardize the features (apply standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the model with scaling\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the scaled test set\n",
        "y_pred_scaled = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model's performance with scaling\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "precision_scaled = precision_score(y_test, y_pred_scaled)\n",
        "recall_scaled = recall_score(y_test, y_pred_scaled)\n",
        "f1_scaled = f1_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Results with Scaling:\")\n",
        "print(f\"Accuracy: {accuracy_scaled * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_scaled * 100:.2f}%\")\n",
        "print(f\"Recall: {recall_scaled * 100:.2f}%\")\n",
        "print(f\"F1-Score: {f1_scaled * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "6uj9zxKgOaMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}